[package]
name = "ai-batch-queue"
version = "0.1.0"
edition = "2021"
authors = ["Josh"]
license = "MIT"
description = "Model-aware batch processing queue with ETA estimation for Tauri applications"
repository = "https://github.com/yourusername/ai-batch-queue"
keywords = ["tauri", "batch", "queue", "ai", "gpu"]
categories = ["asynchronous"]

[dependencies]
tauri = "2"
tokio = { version = "1", features = ["full"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
anyhow = "1"
chrono = { version = "0.4", features = ["serde"] }
uuid = { version = "1", features = ["v4", "serde"] }
thiserror = "2"

[dev-dependencies]
tempfile = "3"

[[example]]
name = "basic_batch"
path = "examples/basic_batch.rs"

[[example]]
name = "model_optimization"
path = "examples/model_optimization.rs"

[[example]]
name = "eta_tracking"
path = "examples/eta_tracking.rs"
